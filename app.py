import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from model_utils import train_model, predict_customers
from ai_assistant import ask_ai

# Load data
data = pd.read_csv("data/marketing_campaign.csv")

st.set_page_config(page_title="Customer Purchase Prediction", layout="wide")
st.title("Predict Customer Purchases with AI")

# Sidebar for navigation
page = st.sidebar.selectbox("Choose a page:", [
    "Data Overview",
    "Feature Selection",
    "Model Training",
    "Customer Comparison",
    "Ask the AI"
])

# Store session state
if "selected_features" not in st.session_state:
    st.session_state.selected_features = []
if "model" not in st.session_state:
    st.session_state.model = None

# Data Overview Page
if page == "Data Overview":
    st.header("üìä Data Overview")
    st.markdown("""
    This app uses a real-world marketing campaign dataset to predict whether a customer will respond to a future campaign.
    
    **Target Variable:**  
    - `Response` (0 = No, 1 = Yes): Did the customer respond to the most recent marketing campaign?

    **Source:**  
    This dataset is based on the ["Customer Personality Analysis"](https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis) dataset from Kaggle, originally released by a Portuguese retail company.

    ---
    """)

    if st.checkbox("üîç Show sample data (first 20 rows)"):
        st.dataframe(data.head(20))

    if st.checkbox("üìö Show column descriptions"):
        st.markdown("""
        **Demographic & Household Info:**
        - `Income`: Yearly income of the customer.
        - `Kidhome`: Number of children in the household.
        - `Teenhome`: Number of teenagers in the household.
        - `Age`: Customer age (engineered).
        - `Customer_Days`: Days since enrollment.

        **Purchase Behavior:**
        - `MntWines`, `MntFruits`, `MntMeatProducts`, `MntFishProducts`, `MntSweetProducts`, `MntGoldProds`: Spending on product categories.
        - `MntTotal`: Total spending.
        - `MntRegularProds`: Spending excluding gold products.

        **Campaign Interaction:**
        - `AcceptedCmp1`‚Äì`AcceptedCmp5`: Responses to previous campaigns.
        - `AcceptedCmpOverall`: Total campaigns accepted.
        - `Response`: Target ‚Äî response to the last campaign.

        **Engagement Metrics:**
        - `Recency`: Days since last purchase.
        - `NumDealsPurchases`, `NumWebPurchases`, `NumCatalogPurchases`, `NumStorePurchases`: Purchase channels.
        - `NumWebVisitsMonth`: Website visits in the last month.

        **Other:**
        - `Complain`: Whether the customer complained.
        - `Z_CostContact`, `Z_Revenue`: Business constants.

        **One-Hot Encoded:**
        - `marital_*`: Marital status.
        - `education_*`: Education level.
        """)

    st.markdown("---")
    st.subheader("üìà Campaign Response Rate")
    response_rate = data["Response"].value_counts(normalize=True).sort_index()
    fig1, ax1 = plt.subplots()
    ax1.bar(["No", "Yes"], response_rate.values, color=["skyblue", "orange"])
    ax1.set_ylabel("Proportion")
    ax1.set_title("Customer Response to Last Campaign")
    st.pyplot(fig1)

    st.markdown("---")
    st.subheader("üí∏ Spending vs. Age")
    fig2, ax2 = plt.subplots()
    ax2.scatter(data["Age"], data["MntTotal"], alpha=0.5)
    ax2.set_xlabel("Age")
    ax2.set_ylabel("Total Spending (MntTotal)")
    ax2.set_title("Customer Spending vs. Age")
    st.pyplot(fig2)

# Feature Selection Page
elif page == "Feature Selection":
    st.header("üîç Select Features You Think Are Important")
    features = [col for col in data.columns if col not in ["ID", "Response"]]
    selected = st.multiselect("Pick your features:", features)
    if st.button("Save Feature Selection"):
        st.session_state.selected_features = selected
        st.success("‚úÖ Features saved! Now go to Model Training.")

# Model Training Page
elif page == "Model Training":
    st.header("üèãÔ∏è Train Model Based on Selected Features")
    if not st.session_state.selected_features:
        st.warning("Please select features first!")
    else:
        with st.spinner("Training model..."):
            model, report, X_test, y_test, feature_names = train_model(data, st.session_state.selected_features)
            st.session_state.model = model
            st.session_state.X_test = X_test
            st.session_state.y_test = y_test
            st.session_state.feature_names = feature_names

        st.success("‚úÖ Model training complete!")

        # Format and show metrics table
        st.subheader("üìã Classification Metrics")
        import numpy as np
        report_df = pd.DataFrame(report).transpose()
        display_metrics = report_df.loc[["0", "1", "accuracy", "macro avg", "weighted avg"]]
        clean_metrics = display_metrics[["precision", "recall", "f1-score", "support"]].round(2)
        st.dataframe(clean_metrics)

        st.markdown("""
        ### üß† What Do These Metrics Mean?
        
        - **Precision** measures how often the model is *correct when it predicts a customer will respond*.  
          Example: If precision is 0.75, then 75% of the customers the model says "yes" to are actual responders.
        
        - **Recall** measures how well the model *finds all the actual responders*.  
          Example: If recall is 0.60, then the model finds 60% of all customers who actually responded.
        
        - **F1-Score** is the balance between precision and recall.  
          It‚Äôs useful when both false positives and false negatives matter.
        
        - **Support** shows the number of actual customers in each class (0 = did not respond, 1 = responded).  
          This tells you whether the dataset is imbalanced.
        
        - **Accuracy** (in the final row) shows the overall percentage of correct predictions.  
          It can be misleading if one class is much larger than the other, so we include precision/recall too.
        
        **In short:**
        - High **precision** ‚Üí You‚Äôre confident in your "yes" predictions.
        - High **recall** ‚Üí You‚Äôre catching most actual responders.
        - High **F1-score** ‚Üí You're balancing both well.
        """)


        # Bar plot: Precision & Recall for Class 0 and 1
        st.subheader("üìä Precision vs. Recall (by Class)")
        import matplotlib.pyplot as plt
        fig, ax = plt.subplots()
        labels = ["Did Not Respond (0)", "Responded (1)"]
        x = np.arange(len(labels))
        width = 0.35
        precision = display_metrics.loc[["0", "1"], "precision"].values
        recall = display_metrics.loc[["0", "1"], "recall"].values
        ax.bar(x - width/2, precision, width, label='Precision', color='skyblue')
        ax.bar(x + width/2, recall, width, label='Recall', color='orange')
        ax.set_ylabel("Score")
        ax.set_ylim(0, 1)
        ax.set_xticks(x)
        ax.set_xticklabels(labels)
        ax.set_title("Model Precision and Recall by Class")
        ax.legend()
        st.pyplot(fig)

        precision1 = report_df.loc["1", "precision"]
        recall1 = report_df.loc["1", "recall"]
        f1_1 = report_df.loc["1", "f1-score"]
        
        # Natural language interpretation
        st.markdown(f"""
        ### üß† Model Interpretation (for Responders)
        
        - **Precision = {precision1:.2f}**  
          ‚Üí When the model predicts a customer *will* respond, it's right {precision1*100:.0f}% of the time.
        
        - **Recall = {recall1:.2f}**  
          ‚Üí The model only identifies {recall1*100:.0f}% of the actual responders ‚Äî meaning it's missing most.
        
        - **F1-Score = {f1_1:.2f}**  
          ‚Üí This low score confirms the model struggles to balance accuracy and completeness for responders.
        
        ---
        
        ### üìå Interpretation:
        The model is **very cautious** about predicting someone will respond ‚Äî and when it does, it's only correct about half the time.  
        However, it's **missing many actual responders**, which means **recall is low**. This is typical when:
        - The positive class (responders) is rare
        - The model isn't yet optimized to catch them
        
        ‚úÖ You can improve this by trying:
        - Resampling (oversampling responders)
        - Tuning the model
        - Using different thresholds instead of 0.5
        """)


        # ROC Curve
        st.subheader("üìâ ROC Curve")
        from sklearn.metrics import roc_curve, auc
        y_score = model.predict_proba(X_test)[:, 1]
        fpr, tpr, _ = roc_curve(y_test, y_score)
        roc_auc = auc(fpr, tpr)
        fig_roc, ax_roc = plt.subplots()
        ax_roc.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="darkorange")
        ax_roc.plot([0, 1], [0, 1], linestyle="--", color="gray")
        ax_roc.set_xlabel("False Positive Rate")
        ax_roc.set_ylabel("True Positive Rate")
        ax_roc.set_title("Receiver Operating Characteristic (ROC)")
        ax_roc.legend()
        st.pyplot(fig_roc)

        # Feature importance
        st.subheader("üîç Feature Importance")
        importances = model.feature_importances_
        feat_df = pd.DataFrame({
            "Feature": feature_names,
            "Importance": importances
        }).sort_values("Importance", ascending=False)

        fig_imp, ax_imp = plt.subplots(figsize=(8, 4))
        ax_imp.barh(feat_df["Feature"][:10][::-1], feat_df["Importance"][:10][::-1], color="slateblue")
        ax_imp.set_xlabel("Importance")
        ax_imp.set_title("Top 10 Important Features")
        st.pyplot(fig_imp)


# Customer Comparison Page
elif page == "Customer Comparison":
    st.header("üßë‚Äçü§ù‚Äçüßë Compare Two Customers")
    if st.session_state.model is None:
        st.warning("Please train the model first!")
    else:
        customer_idx1 = st.number_input("Select Customer A Row Number", min_value=0, max_value=len(data)-1, value=0)
        customer_idx2 = st.number_input("Select Customer B Row Number", min_value=0, max_value=len(data)-1, value=1)
        pred1, pred2 = predict_customers(data, customer_idx1, customer_idx2, st.session_state)
        st.write(f"**Customer A Purchase Probability:** {pred1:.2f}")
        st.write(f"**Customer B Purchase Probability:** {pred2:.2f}")

# Ask the AI Page
elif page == "Ask the AI":
    st.header("üí¨ Ask the AI about the Model")
    if st.session_state.model is None:
        st.warning("Please train the model first!")
    else:
        user_question = st.text_input("Your Question:")
        if user_question:
            answer = ask_ai(user_question, st.session_state)
            st.write("### AI Answer:")
            st.write(answer)
